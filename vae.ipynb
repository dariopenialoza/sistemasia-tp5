{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import copy\n",
    "from src.utils import DataConfig, alter_data\n",
    "from src.autoencoder import Autoencoder\n",
    "from src.plots import *\n",
    "\n",
    "with open('./config_variational.json', 'r') as f:\n",
    "    data_config = json.load(f)\n",
    "\n",
    "c = DataConfig(data_config)\n",
    "\n",
    "OPTIMIZACIONES = [\"ADAM\", \"MOMENTUM\", \"NONE\"]\n",
    "\n",
    "arr_of_errors = []\n",
    "arr_of_epochs = []\n",
    "for i in range(len(OPTIMIZACIONES)):\n",
    "    autoencoder = Autoencoder(c.input_data, c.input_data, c.latent_space_size,\n",
    "                            c.learning_rate, c.bias, c.epochs, 1,\n",
    "                            c.min_error, c.qty_hidden_layers, c.qty_nodes_in_hidden_layers,\n",
    "                            c.output_activation, c.hidden_activation, c.beta,\n",
    "                            OPTIMIZACIONES[i], c.alpha, c.beta1, c.beta2,\n",
    "                            c.epsilon)\n",
    "    mse_errors, total_epochs = autoencoder.train()\n",
    "    arr_of_errors.append(mse_errors)\n",
    "    arr_of_epochs.append(total_epochs)\n",
    "\n",
    "colors = ['blue', 'green', 'red', 'orange']\n",
    "\n",
    "fig, ax = plt.subplots()  \n",
    "for i, arquitectura in enumerate(OPTIMIZACIONES):\n",
    "    ax.plot(range(arr_of_epochs[i]), arr_of_errors[i],  label=f\"{OPTIMIZACIONES[i]}\") \n",
    "ax.set_title('Error para distintas optimizaciones') \n",
    "ax.set_xlabel('Epocas') \n",
    "ax.set_ylabel('Error (MSE)')  \n",
    "ax.legend(loc='best' )   \n",
    "plt.show()  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
